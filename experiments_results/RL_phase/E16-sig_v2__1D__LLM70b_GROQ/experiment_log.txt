### E16-sig_v2__1D__LLM70b_GROQ ###

Config
-------------------
Seed: 2
Agent First Strategy: random
Agent Policy: dqn
Random Suggestion: False

Board Representation: 1D
Cross Representation: 1/-1
DSPY Signature: v2
LLM Config
-------------------
Save LLM Cache: False
LLM Load Path: None
LLM Model ID: llama3-70b-8192

Learning Config
-------------------
Batch Size: 32
Learning Rate: 0.0001
Gamma: 0.99
Target Update Steps: 30

Training
-------------------
Training Episodes: 1000
LLM Use Probability (Training): 1
Training Time: 3094.91 seconds
Evaluation
-------------------
Total Games: 100
LLM Use Probability (Evaluation): 1
Win: 62 (62.00%)
Loss: 17 (17.00%)
Draw: 21 (21.00%)
Evaluation Time: 73.32 seconds

